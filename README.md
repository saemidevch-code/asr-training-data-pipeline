# asr-training-data-pipeline
Research-grade audio extraction pipeline for ASR training with zero-phantom word design
# Repository Structure Guide

Complete folder organization for your ASR pipeline repo.

## Directory Structure

```
asr-training-data-pipeline/
├── README.md                          # Main documentation (already created)
├── LICENSE                            # MIT License (auto-generated by GitHub)
├── .gitignore                         # Python gitignore (auto-generated by GitHub)
├── requirements.txt                   # Python dependencies
├── claude_research_optimal.py         # Main pipeline script
│
├── examples/                          # Sample outputs (optional but recommended)
│   ├── sample_clips.tsv               # Example metadata output
│   ├── sample_summary.json            # Example processing statistics
│   └── README.md                      # Explanation of examples
│
└── docs/                              # Detailed documentation (optional)
    ├── INSTALLATION.md                # Detailed setup instructions
    ├── ARCHITECTURE.md                # Technical architecture details
    ├── PARAMETERS.md                  # Complete parameter reference
    └── TROUBLESHOOTING.md             # Common issues and solutions
```

---

## What to Put in Each File

### Root Files (Required)

**README.md**
- Already created in artifact above
- Main entry point for anyone visiting your repo
- Copy from artifact to your local repo

**requirements.txt**
- Already created in artifact above
- Lists all Python dependencies
- Copy from artifact to your local repo

**claude_research_optimal.py**
- Your main script
- Copy from: `C:\temp\out\ch01\clauderesearchgptresearchpro\claude\claude_research_optimal.py`
- This is the actual pipeline code

**LICENSE**
- Auto-generated when you created the repo
- MIT License allows open use
- Don't need to modify

**.gitignore**
- Auto-generated when you selected "Python" template
- Tells Git to ignore temporary files, cache, etc.
- Don't need to modify unless you have specific needs

---

## Optional: examples/ Folder

**Purpose:** Show what the pipeline outputs look like

**Create this if:**
- You want to help users understand the output format
- You're applying for jobs (shows attention to detail)
- You plan to make repo public

**What to include:**

`examples/sample_clips.tsv` (3-5 lines from actual output):
```
path	start	end	duration_s	words	pieces	avg_conf	acoustic_quality
clips/segment_0000.wav	0.000	4.532	4.532	12	1	0.856	clean
clips/segment_0001.wav	0.000	3.218	3.218	8	1	0.912	clean
```

`examples/sample_summary.json`:
```json
{
  "exported": 56,
  "rejected": 2,
  "rejection_rate_pct": 3.45,
  "equal_runs": 93,
  "bridged_groups": 58,
  "whisperx_model": "large-v3",
  "validator": "medium.en"
}
```

`examples/README.md`:
```markdown
# Example Outputs

Sample outputs from processing a 15-minute sermon audio file.

## Files

- `sample_clips.tsv`: Metadata for exported segments
- `sample_summary.json`: Processing statistics

## Notes

- Processing time: ~12 minutes on RTX 3090
- Input: 15:32 audio, 3743 words in transcript
- Output: 56 segments, 3.4% rejection rate
- Average segment confidence: 0.822
```

---

## Optional: docs/ Folder

**Purpose:** Detailed technical documentation

**Create this if:**
- You want to document complex decisions
- You're making this a "serious" open-source project
- You need reference material for yourself

**You can skip this initially** - the README is sufficient for getting started.

**If you do create it:**

`docs/INSTALLATION.md`:
```markdown
# Detailed Installation Guide

## Prerequisites

### Windows
- Python 3.8+ with pip
- Git for Windows
- CUDA toolkit 11.8+ (for GPU)
- Visual Studio Build Tools (for some pip packages)

### Installation Steps

1. Install system dependencies...
2. Create virtual environment...
3. Install PyTorch with CUDA...
4. Install other dependencies...

[Detailed step-by-step with troubleshooting]
```

`docs/ARCHITECTURE.md`:
```markdown
# Pipeline Architecture

## Overview
[Detailed explanation of each stage]

## Design Decisions
[Why these choices were made]

## Data Flow
[How data moves through the pipeline]
```

`docs/PARAMETERS.md`:
```markdown
# Complete Parameter Reference

## Required Parameters
--audio: Path to input audio
--text: Path to reference transcript
--outdir: Output directory

## Optional Parameters
[Every parameter with detailed explanation]
```

`docs/TROUBLESHOOTING.md`:
```markdown
# Common Issues

## WhisperX Import Error
**Symptom:** `ModuleNotFoundError: No module named 'whisperx'`
**Solution:** Install with git+https://...

[More issues and solutions]
```

---

## What to Commit First (Minimum Viable Repo)

**Essential files only:**
```
asr-training-data-pipeline/
├── README.md                    # Copy from artifact
├── requirements.txt             # Copy from artifact
└── claude_research_optimal.py   # Your script
```

This is enough to:
- Show your code
- Explain what it does
- Let others install dependencies

**Skip for now:**
- `examples/` folder (add later after running pipeline)
- `docs/` folder (add if you make this a serious project)

---

## Recommended: Add Later

After you've run the pipeline and have real outputs:

1. Create `examples/` with sample outputs
2. Update README with actual performance numbers
3. Add screenshots if helpful
4. Consider `docs/` if the README gets too long

---

## Files to NEVER Commit

Your `.gitignore` already handles most of these, but avoid:

❌ Audio files (too large, use Git LFS if needed)
❌ Output clips (too large)
❌ API keys or passwords
❌ Personal data or transcripts with private info
❌ Temporary files (`.pyc`, `__pycache__`, etc.)

✅ Code files (`.py`)
✅ Documentation (`.md`)
✅ Configuration (`.txt`, `.json` configs)
✅ Small example outputs (<100KB)

---

## Summary: What You Need Right Now

**Create locally:**
1. `README.md` - copy from artifact
2. `requirements.txt` - copy from artifact  
3. `claude_research_optimal.py` - copy your existing script

**Commit order:**
```bash
cd C:\projects\asr-training-data-pipeline

# Copy files here
# Then:

git add README.md
git add requirements.txt  
git add claude_research_optimal.py
git commit -m "Initial commit: Core pipeline with documentation"
git push origin main
```

**Add later (optional):**
- `examples/` after you have real outputs
- `docs/` if README gets too long or you want detailed references

Start simple. You can always add more structure later.